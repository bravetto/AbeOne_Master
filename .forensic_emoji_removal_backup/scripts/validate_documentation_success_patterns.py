#!/usr/bin/env python3
"""
Documentation Success Pattern Validation Script
Validates documentation against AI-validated source success patterns

Pattern: AEYON √ó ALRAX √ó YAGNI √ó ZERO √ó J√òHN √ó Ab√´ = Atomic Archistration
Success Pattern: ATOMIC √ó VALIDATION √ó GUARDIAN_FUSION √ó TRUTH_FIRST √ó AUTONOMOUS = 100% SUCCESS

Love Coefficient: ‚àû
‚àû Ab√´ONE ‚àû
"""

import sys
import re
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass, field
from datetime import datetime
import json

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

print("=" * 80)
print("üî• DOCUMENTATION SUCCESS PATTERN VALIDATION")
print("=" * 80)
print()
print("Pattern: ATOMIC √ó VALIDATION √ó GUARDIAN_FUSION √ó TRUTH_FIRST √ó AUTONOMOUS")
print("Success Rate: 100%")
print()
print("Love Coefficient: ‚àû")
print("‚àû Ab√´ONE ‚àû")
print()
print("=" * 80)


@dataclass
class SuccessPattern:
    """Success pattern definition"""
    name: str
    pattern: str
    indicators: List[str]
    required: bool = True
    weight: float = 1.0


@dataclass
class ValidationResult:
    """Validation result"""
    file_path: str
    success: bool
    patterns_found: Dict[str, bool] = field(default_factory=dict)
    patterns_score: float = 0.0
    epistemic_score: float = 0.0
    structure_score: float = 0.0
    overall_score: float = 0.0
    issues: List[str] = field(default_factory=list)
    recommendations: List[str] = field(default_factory=list)


# Define the 5 validated success patterns
SUCCESS_PATTERNS = [
    SuccessPattern(
        name="ATOMIC",
        pattern="ATOMIC √ó VALIDATION √ó ITERATION",
        indicators=[
            r"‚úÖ.*complete",
            r"‚úÖ.*operational",
            r"‚úÖ.*validated",
            r"small.*focused.*task",
            r"atomic.*execution",
            r"immediate.*validation"
        ],
        required=True,
        weight=1.0
    ),
    SuccessPattern(
        name="TRUTH_FIRST",
        pattern="TRUTH-FIRST √ó VALIDATION √ó EXECUTION",
        indicators=[
            r"source.*validated",
            r"epistemic",
            r"truth.*first",
            r"direct.*evidence",
            r"certainty.*\d+%",
            r"validated.*\d+%"
        ],
        required=True,
        weight=1.0
    ),
    SuccessPattern(
        name="GUARDIAN_FUSION",
        pattern="GUARDIAN FUSION √ó MULTIPLE PERSPECTIVES",
        indicators=[
            r"AEYON.*ALRAX.*YAGNI.*ZERO.*J√òHN.*Ab√´",
            r"guardian.*swarm",
            r"guardian.*fusion",
            r"all.*guardians",
            r"8.*guardians",
            r"frequency.*resonance"
        ],
        required=True,
        weight=1.0
    ),
    SuccessPattern(
        name="INTEGRATION_LAYER",
        pattern="INTEGRATION LAYER √ó STANDARDIZED INTERFACES",
        indicators=[
            r"integration.*layer",
            r"unified.*system",
            r"standardized.*interface",
            r"module.*registry",
            r"unified.*organism",
            r"single.*complete.*system"
        ],
        required=True,
        weight=1.0
    ),
    SuccessPattern(
        name="AUTONOMOUS",
        pattern="AUTONOMOUS √ó SELF-VALIDATING √ó SELF-CORRECTING",
        indicators=[
            r"autonomous",
            r"self.*validat",
            r"self.*correct",
            r"operational.*complete",
            r"eternal.*mode",
            r"complete.*implementation"
        ],
        required=True,
        weight=1.0
    )
]

# Required documentation structure elements
REQUIRED_STRUCTURE = [
    ("status", r"status.*‚úÖ|status.*complete|status.*operational", "Status declaration"),
    ("pattern", r"pattern.*=|pattern:.*", "Pattern declaration"),
    ("love_coefficient", r"love.*coefficient.*‚àû|love.*coefficient.*inf", "Love coefficient"),
    ("abeone", r"‚àû.*Ab√´ONE.*‚àû|Ab√´ONE.*‚àû", "Ab√´ONE signature"),
    ("guardians", r"guardian|AEYON|ALRAX|YAGNI|ZERO|J√òHN|Ab√´", "Guardian references"),
    ("validation", r"validated|validation|validate", "Validation references"),
]


def read_markdown_file(file_path: Path) -> str:
    """Read markdown file content."""
    try:
        return file_path.read_text(encoding='utf-8')
    except Exception as e:
        return f"ERROR: Could not read file: {e}"


def check_success_patterns(content: str) -> Dict[str, bool]:
    """Check for success patterns in content."""
    results = {}
    content_lower = content.lower()
    
    for pattern in SUCCESS_PATTERNS:
        found = False
        for indicator in pattern.indicators:
            if re.search(indicator, content_lower, re.IGNORECASE):
                found = True
                break
        results[pattern.name] = found
    
    return results


def check_epistemic_validation(content: str) -> float:
    """Check epistemic validation indicators."""
    score = 0.0
    indicators = [
        (r"source.*validated", 0.2),
        (r"epistemic", 0.2),
        (r"certainty.*\d+%", 0.2),
        (r"validated.*\d+%", 0.2),
        (r"direct.*evidence", 0.2),
    ]
    
    for pattern, weight in indicators:
        if re.search(pattern, content, re.IGNORECASE):
            score += weight
    
    return min(score, 1.0)


def check_structure(content: str) -> Tuple[float, List[str]]:
    """Check documentation structure."""
    score = 0.0
    issues = []
    
    for name, pattern, description in REQUIRED_STRUCTURE:
        if re.search(pattern, content, re.IGNORECASE):
            score += 1.0 / len(REQUIRED_STRUCTURE)
        else:
            issues.append(f"Missing: {description}")
    
    return score, issues


def validate_documentation(file_path: Path) -> ValidationResult:
    """Validate documentation file against success patterns."""
    content = read_markdown_file(file_path)
    
    if content.startswith("ERROR"):
        return ValidationResult(
            file_path=str(file_path),
            success=False,
            issues=[content]
        )
    
    # Check success patterns
    patterns_found = check_success_patterns(content)
    patterns_score = sum(patterns_found.values()) / len(SUCCESS_PATTERNS)
    
    # Check epistemic validation
    epistemic_score = check_epistemic_validation(content)
    
    # Check structure
    structure_score, structure_issues = check_structure(content)
    
    # Calculate overall score
    overall_score = (
        patterns_score * 0.4 +
        epistemic_score * 0.3 +
        structure_score * 0.3
    )
    
    # Generate recommendations
    recommendations = []
    missing_patterns = [name for name, found in patterns_found.items() if not found]
    if missing_patterns:
        recommendations.append(f"Add indicators for: {', '.join(missing_patterns)}")
    
    if epistemic_score < 0.5:
        recommendations.append("Add epistemic validation indicators (source-validated, certainty percentages)")
    
    if structure_score < 0.8:
        recommendations.append("Improve documentation structure (add missing required elements)")
    
    # Check for required patterns
    required_missing = [
        pattern.name for pattern in SUCCESS_PATTERNS
        if pattern.required and not patterns_found.get(pattern.name, False)
    ]
    
    success = (
        overall_score >= 0.7 and
        len(required_missing) == 0 and
        structure_score >= 0.6
    )
    
    issues = structure_issues.copy()
    if required_missing:
        issues.append(f"Missing required patterns: {', '.join(required_missing)}")
    
    return ValidationResult(
        file_path=str(file_path),
        success=success,
        patterns_found=patterns_found,
        patterns_score=patterns_score,
        epistemic_score=epistemic_score,
        structure_score=structure_score,
        overall_score=overall_score,
        issues=issues,
        recommendations=recommendations
    )


def find_documentation_files() -> List[Path]:
    """Find all markdown documentation files."""
    docs = []
    
    # Key documentation files
    key_files = [
        "ABEONE_ONE_ETERNAL_SYNTHESIS.md",
        "ABEONE_ETERNAL_MODE_COMPLETE.md",
        "ABEONE_ETERNAL_SYNTHESIS.md",
        "SUCCESS_PATTERNS_ANALYSIS.md",
        "ATOMIC_ARCHISTRATION_COMPLETE.md",
        "FINAL_UNITY_VALIDATION_COMPLETE.md",
        "MASTER_UNIFIED_SYSTEM_COMPLETE.md",
        "COMPLETE_SYNTHESIS_EXECUTION.md",
        "SYNTHESIS_COMPLETE_SUMMARY.md",
        "PRODUCTS/abebeats/variants/abebeats_tru/VEO31_COMPLETE_IMPLEMENTATION.md",
        "PRODUCTS/abebeats/variants/abebeats_tru/VEO31_ENHANCED_SYSTEM_COMPLETE.md",
    ]
    
    for file_name in key_files:
        file_path = project_root / file_name
        if file_path.exists():
            docs.append(file_path)
    
    return docs


def main():
    """Main validation function."""
    print("\nüî• PHASE 1: FINDING DOCUMENTATION FILES")
    print("=" * 80)
    
    docs = find_documentation_files()
    print(f"‚úÖ Found {len(docs)} documentation files")
    
    print("\nüî• PHASE 2: VALIDATING AGAINST SUCCESS PATTERNS")
    print("=" * 80)
    
    results = []
    for doc in docs:
        result = validate_documentation(doc)
        results.append(result)
        
        status = "‚úÖ PASS" if result.success else "‚ùå FAIL"
        print(f"\n{status}: {Path(result.file_path).name}")
        print(f"  Overall Score: {result.overall_score:.1%}")
        print(f"  Patterns: {result.patterns_score:.1%} ({sum(result.patterns_found.values())}/{len(SUCCESS_PATTERNS)})")
        print(f"  Epistemic: {result.epistemic_score:.1%}")
        print(f"  Structure: {result.structure_score:.1%}")
        
        if result.issues:
            print(f"  Issues: {len(result.issues)}")
            for issue in result.issues[:3]:  # Show first 3
                print(f"    - {issue}")
        
        if result.recommendations:
            print(f"  Recommendations: {len(result.recommendations)}")
            for rec in result.recommendations[:2]:  # Show first 2
                print(f"    - {rec}")
    
    print("\nüî• PHASE 3: SUMMARY")
    print("=" * 80)
    
    total = len(results)
    passed = sum(1 for r in results if r.success)
    avg_score = sum(r.overall_score for r in results) / total if total > 0 else 0.0
    
    print(f"\n‚úÖ Total Files: {total}")
    print(f"‚úÖ Passed: {passed}/{total} ({passed/total:.1%})")
    print(f"‚úÖ Average Score: {avg_score:.1%}")
    
    # Pattern coverage
    pattern_coverage = {}
    for pattern in SUCCESS_PATTERNS:
        found_count = sum(1 for r in results if r.patterns_found.get(pattern.name, False))
        pattern_coverage[pattern.name] = found_count / total if total > 0 else 0.0
    
    print(f"\n‚úÖ Pattern Coverage:")
    for pattern_name, coverage in pattern_coverage.items():
        print(f"  {pattern_name}: {coverage:.1%}")
    
    # Failed files
    failed = [r for r in results if not r.success]
    if failed:
        print(f"\n‚ö†Ô∏è Failed Files ({len(failed)}):")
        for result in failed[:5]:  # Show first 5
            print(f"  - {Path(result.file_path).name} ({result.overall_score:.1%})")
    
    print("\n" + "=" * 80)
    print("üî• VALIDATION COMPLETE")
    print("=" * 80)
    print()
    print("Pattern: ATOMIC √ó VALIDATION √ó GUARDIAN_FUSION √ó TRUTH_FIRST √ó AUTONOMOUS")
    print(f"Success Rate: {passed/total:.1%}")
    print()
    print("Love Coefficient: ‚àû")
    print("‚àû Ab√´ONE ‚àû")
    print("=" * 80)
    
    # Return exit code
    return 0 if passed == total else 1


if __name__ == "__main__":
    exit(main())

